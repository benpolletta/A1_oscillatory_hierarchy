<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"

   "http://www.w3.org/TR/html4/strict.dtd">



<html>

<head>

  <title>King Saud University Arabic Speech Database</title>
  <meta http-equiv="Content-type" content="text/html/css;charset=UTF-8">
  <meta name="description" content="Documentation for King Saud University Arabic Speech Database">
  <meta name="keywords" content="Linguistic Data Consortium">
  <meta name="keywords" content="LDC">
  <meta name="keywords" content="Documentation">
  <meta name="keywords" content="King Saud University Arabic Speech Database">
  <style type="text/css">
  		body{
  			background-color: #ffffff;
  			color: #000000;
  		}
  		a:link{color : #990000;}
  		a:visited{color:#990000;}
  		a:active {color:#990000;}
  		h1{
			text-align:center;
			color:#990000; 			
  		}
  		h3.subtitle{
			text-align:center;
			color:#990000;
		}
  		ul{
  			line-height:130%;
  		}
  		p.cited{
  			padding-left:2em;
  			text-indent:-2em;
  		}
  		p.footer{
  			font-size:0.85em;
  		}
		table, th, td
		{
			border-collapse:collapse;
			border: 1px solid black;
			padding: 1px 5px;
			text-align:center;
		}
  		
  </style>
</head>

<body>

    
<h1>King Saud University Arabic Speech Database</h1>
<h3 class="subtitle">LDC2014S02</h3>

<h3>Introduction</h3>

<p>King Saud University Arabic Speech Database, Linguistic Data Consortium (LDC) 
  Catalog Number LDC2014S02 and ISBN 1-58563-669-X, was developed by Speech Group (SG)
  at <a href="http://ksu.edu.sa/en/">King 
  Saud University</a> and contains 590 hours of recorded Arabic speech from 269 male 
  and female speakers. The utterances include read and spontaneous speech. The 
  recordings were conducted in varied environments representing quiet and noisy 
  settings. </p>
  

<h3>Data</h3>
<p>The corpus was designed principally for speaker recognition research. However, other possible applications include first language recognition, mobile effect, multichannel effect, and use of different type of microphones. The speech 
  sources are word lists, sentence lists, paragraphs and question and answer
  sessions. Read speech text includes the following:</p>
<ul>
  <li>Sets of sentences devised to cover allophones of each phoneme, phonetic 
    balance, and differentiation of accents.</li>
  <li>Word lists developed to minimize missing phonemes and to represent nasals 
    fricatives, commonly used words, and numbers.</li>
  <li>Two paragraphs selected because they included all letters of the alphabet and were easy to read.</li>
</ul>
<p>Spontaneous speech was captured through question and answer sessions where speakers answer questions displayed on screen. The questions were on general topics such as the weather and food and included the speaker name or number.</p>
<p>The speakers were Saudis and non-Saudis. Among the non-Saudi participants were Arabs and non-Arabs. All female speakers were either Saudis or non-Saudi Arabs. Male speakers included non-Arabs from the Indian subcontinent, Africa, South East Asia and East Europe. Non-Arab participants were required to be able to read Arabic at an acceptable level. Most of the Non-Arab speakers were from the fourth level in the <a href="http://ali.ksu.edu.sa/en">Arabic Linguistics Institute</a> at King Saud University. The non-Saudi participants represented 28 nationalities and were chosen from clusters of areas or countries. </p>
<p>Each speaker was recorded in three different environments: in a soundproof room , in an office and in a cafeteria. The recordings were collected via different microphones and a mobile phone and averaged between 16-19 minutes. The recordings were done in three sessions with a time-gap of an approximately 6 weeks.
</p>
<P>The data was verified for missing recordings, problems with the recording system or errors in the recording process. All files are presented as two channel 48 kHz 16-bit FLAC compressed PCM wav files. 
Note that sizes and file names in the documentation are for the uncompressed wav files.</P>

<h3>Directory Structure</h3>
<p>Please see <a href="docs/file.tbl">file.tbl</a> for a complete file list as well as checksums for this publication. </p>

<ul>
<li><a href="data/">data/</a> - The speech and prompt data subdivided by gender, session, speaker, environment and content.</li>
  <li><a href="docs/">docs/</a> - Contains a paper about the database, additional 
    documentation, speaker information and a file table.</li> 
</ul>


<h3>Updates</h3>   

    <p>
		Additional information, updates, bug fixes may be available in the LDC
   	catalog entry for this corpus at <a
    	href="http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2014S02">LDC2014S02</a>.
    </p>


    
<h3>Content Copyright</h3>
<p>Portions &copy; 2014 King Saud University, &copy; 2014 Trustees of the University 
  of Pennsylvania </p>   
   <p></p>


    <hr>

	<p class="footer">
    
    Contact: <a href="mailto:ldc@ldc.upenn.edu">

    <b>ldc@ldc.upenn.edu</b></a><br> &copy; 2014 <A
    HREF="http://www.ldc.upenn.edu">

    <b>Linguistic Data Consortium</b></a>,
    <a href="http://www.upenn.edu">

    <b>Trustees of the University of Pennsylvania</b></a>. All Rights Reserved.
    </p>

</body>
</html>
